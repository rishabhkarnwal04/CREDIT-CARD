{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "3DWJjvrg4JYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('creditcard.csv')"
      ],
      "metadata": {
        "id": "8LofjJyz4MgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "y-yrhCZB4XMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "z4AVk6aqF64d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "bEmgFRrl4Z_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "BUmmoeOG4dA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=data, x='Class', palette='Set2')\n",
        "plt.title('Fraud vs Non-Fraud Transactions')\n",
        "plt.xlabel('Class (0: Non-Fraud, 1: Fraud)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iNuPYks84s4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=data, x='Time', y='Amount', hue='Class', palette='Set1')\n",
        "plt.title('Time vs Transaction Amount')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Transaction Amount')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J-g9omL34-0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=data, x='Class', y='Amount', palette='Set3')\n",
        "plt.title('Transaction Amount by Class (Fraud vs Non-Fraud)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Transaction Amount')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9mrMjAnX5DgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "QSXHGc4B5RGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "legit = data[data.Class == 0]\n",
        "fraud = data[data.Class == 1]\n"
      ],
      "metadata": {
        "id": "6mjXmQ8q5Z-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(legit.shape)\n",
        "print(fraud.shape)"
      ],
      "metadata": {
        "id": "K350DhD65cUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "legit.Amount.describe()"
      ],
      "metadata": {
        "id": "oUC6jF3x5ehh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud.Amount.describe()"
      ],
      "metadata": {
        "id": "_o0XUM_e5gr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('Class').mean()"
      ],
      "metadata": {
        "id": "AqJLKeBP5wp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "legit_sample = legit.sample(n=492)"
      ],
      "metadata": {
        "id": "uFNGAjWM5yo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = pd.concat([legit_sample, fraud], axis=0)"
      ],
      "metadata": {
        "id": "Il1NcFSq53tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.head()"
      ],
      "metadata": {
        "id": "m0T-7FCZ55n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.describe()"
      ],
      "metadata": {
        "id": "5h96mE67GQkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset['Class'].value_counts()"
      ],
      "metadata": {
        "id": "FMhuEuQyoSW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.groupby('Class').mean()"
      ],
      "metadata": {
        "id": "PLYhJuQsrCJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = new_dataset.drop(columns='Class', axis=1)\n",
        "Y = new_dataset['Class']\n",
        "X"
      ],
      "metadata": {
        "id": "3yFkjLJErLcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "id": "6STUiBMWrPkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
      ],
      "metadata": {
        "id": "OS94H2ZKrR3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "Pg5_JMzurV14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "EcrbSIV_rYJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "4sz04b9QraHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy on Training data : ', training_data_accuracy)"
      ],
      "metadata": {
        "id": "559tSxClrc3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score on Test Data : ', test_data_accuracy)"
      ],
      "metadata": {
        "id": "Vl-h-LPqrhwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, name):\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    roc_auc = roc_auc_score(Y_test, model.predict_proba(X_test)[:, 1])\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(Y_test, Y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(Y_test, Y_pred))\n",
        "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "6P6scCzxEDKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "S0SR9rm-GNg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    evaluate_model(model, name)\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "    evaluate_model(xgb_model, \"XGBoost\")\n",
        "except ImportError:\n",
        "    print(\"XGBoost not installed. Skipping XGBoost model.\")"
      ],
      "metadata": {
        "id": "YNYsKJ2GEEVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_conf_matrix(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix: {title}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc(model, X_test, Y_test, name):\n",
        "    fpr, tpr, _ = roc_curve(Y_test, model.predict_proba(X_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc_score(Y_test, model.predict_proba(X_test)[:, 1]):.2f})')"
      ],
      "metadata": {
        "id": "1YcwFoJiGdVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    print(f\"\\n{name}\")\n",
        "    print(classification_report(Y_test, Y_pred))\n",
        "    plot_conf_matrix(Y_test, Y_pred, name)\n",
        "    plot_roc(model, X_test, Y_test, name)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curves\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_yk6gojwljE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "AorMB2zjGp_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, scoring='f1', cv=3, verbose=2, n_jobs=-1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "best_model = grid.best_estimator_\n",
        "Y_pred = best_model.predict(X_test)\n",
        "print(\"\\nTuned Random Forest\")\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "plot_conf_matrix(Y_test, Y_pred, \"Tuned Random Forest\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VxD26oXNGnKa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}